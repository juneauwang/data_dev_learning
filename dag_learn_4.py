from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.dummy import DummyOperator # 1.10.x å¯èƒ½æ˜¯ DummyOperator
from airflow.utils.dates import days_ago
import random

def check_data_availability():
    # æ¨¡æ‹Ÿæ£€æŸ¥ï¼š50% æ¦‚çŽ‡æœ‰æ•°æ®
    has_data = random.choice([True, False])
    print(f"æ•°æ®æ£€æŸ¥ç»“æžœ: {'æœ‰æ•°æ®' if has_data else 'æ— æ•°æ®'}")
    
    if has_data:
        return 'run_pandas_etl' # è¿”å›žä¸‹ä¸€ä¸ªè¦è¿è¡Œçš„ task_id
    else:
        return 'skip_notification'

def etl_logic():
    print("ðŸš€ æ­£åœ¨æ‰§è¡Œå¤æ‚çš„ ETL é€»è¾‘...")

def notify_logic():
    print("ðŸ“¢ é€šçŸ¥ï¼šä»Šæ—¥æ— æ–°æ•°æ®ï¼Œæµç¨‹ç»“æŸã€‚")

with DAG(
    'smart_branching_workflow_v1',
    start_date=days_ago(1),
    schedule_interval=None,
    catchup=False
) as dag:

    # åˆ†æ”¯èŠ‚ç‚¹
    branching = BranchPythonOperator(
        task_id='branching_node',
        python_callable=check_data_availability
    )

    # è·¯å¾„ A
    run_etl = PythonOperator(
        task_id='run_pandas_etl',
        python_callable=etl_logic
    )

    # è·¯å¾„ B
    skip_notify = PythonOperator(
        task_id='skip_notification',
        python_callable=notify_logic
    )

    # å®šä¹‰ä¾èµ–å…³ç³»
    branching >> [run_etl, skip_notify]
